{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.085631</td>\n",
       "      <td>-0.678886</td>\n",
       "      <td>0.737369</td>\n",
       "      <td>-0.781307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997345</td>\n",
       "      <td>-0.094709</td>\n",
       "      <td>1.490732</td>\n",
       "      <td>0.719068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.282978</td>\n",
       "      <td>1.491390</td>\n",
       "      <td>-0.935834</td>\n",
       "      <td>0.523621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.506295</td>\n",
       "      <td>-0.638902</td>\n",
       "      <td>1.175829</td>\n",
       "      <td>-0.977865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.578600</td>\n",
       "      <td>-0.443982</td>\n",
       "      <td>-1.253881</td>\n",
       "      <td>-0.605743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.651437</td>\n",
       "      <td>-0.434351</td>\n",
       "      <td>-0.637752</td>\n",
       "      <td>0.796781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-2.426679</td>\n",
       "      <td>2.205930</td>\n",
       "      <td>0.907105</td>\n",
       "      <td>-0.703518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.428913</td>\n",
       "      <td>2.186786</td>\n",
       "      <td>-1.428681</td>\n",
       "      <td>0.255820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.265936</td>\n",
       "      <td>1.004054</td>\n",
       "      <td>-0.140069</td>\n",
       "      <td>1.046771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.866740</td>\n",
       "      <td>0.386186</td>\n",
       "      <td>-0.861755</td>\n",
       "      <td>-0.490364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3         y\n",
       "0 -1.085631 -0.678886  0.737369 -0.781307\n",
       "1  0.997345 -0.094709  1.490732  0.719068\n",
       "2  0.282978  1.491390 -0.935834  0.523621\n",
       "3 -1.506295 -0.638902  1.175829 -0.977865\n",
       "4 -0.578600 -0.443982 -1.253881 -0.605743\n",
       "5  1.651437 -0.434351 -0.637752  0.796781\n",
       "6 -2.426679  2.205930  0.907105 -0.703518\n",
       "7 -0.428913  2.186786 -1.428681  0.255820\n",
       "8  1.265936  1.004054 -0.140069  1.046771\n",
       "9 -0.866740  0.386186 -0.861755 -0.490364"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# set numpy seed for reproducibility\n",
    "np.random.seed(123)\n",
    "# create a 1D numpy array \"x1\" with 10 normally distributed random numbers\n",
    "x1 = np.random.randn(10)\n",
    "x2 = np.random.randn(10)\n",
    "x3 = np.random.randn(10)\n",
    "# y is a 1D numpy array with 10 elements that are the weighted sum of x1, x2, and x3 with weights 0.6, 0.3, and 0.1 respectively\n",
    "y = 0.6*x1 + 0.3*x2 + 0.1*x3\n",
    "\n",
    "# y is a numpy array with 10 random binary 0/1 values\n",
    "# y = np.random.randint(0, 2, size=10)\n",
    "\n",
    "df = pd.DataFrame({'x1': x1, 'x2': x2, 'x3': x3, 'y': y})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/edd55b80-acb0-4d97-8534-ecb522d0a043\n",
    "\n",
    "\n",
    "```\n",
    "class DecisionTreeRegressor:\n",
    "    def __init__(self, max_depth=None):\n",
    "        # Initialize the decision tree regressor\n",
    "        self.max_depth = max_depth  # Maximum depth the tree can grow to\n",
    "        self.tree = None  # This will store the built tree structure\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Fit the decision tree to the training data\n",
    "        self.tree = self._build_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Predict the target values for the input samples\n",
    "        return np.array([self._predict_sample(sample, self.tree) for sample in X])\n",
    "\n",
    "    def _mse(self, y):\n",
    "        # Calculate the mean squared error of the target values\n",
    "        if len(y) == 0:\n",
    "            return 0  # To handle division by zero in case of empty split\n",
    "        mean = np.mean(y)\n",
    "        return np.mean((y - mean) ** 2)\n",
    "\n",
    "    def _information_gain(self, y, y_left, y_right):\n",
    "        # Calculate the reduction in mean squared error after a split\n",
    "        parent_mse = self._mse(y)  # MSE of the parent node\n",
    "        n = len(y)  # Total number of samples\n",
    "        n_left, n_right = len(y_left), len(y_right)  # Number of samples in left and right nodes\n",
    "        if n_left == 0 or n_right == 0:\n",
    "            return 0  # If any split is empty, the information gain is zero\n",
    "        # Weighted average MSE of the child nodes\n",
    "        weighted_avg_mse = (n_left / n) * self._mse(y_left) + (n_right / n) * self._mse(y_right)\n",
    "        # Information gain is the reduction in MSE\n",
    "        return parent_mse - weighted_avg_mse\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        # Find the best split for the data\n",
    "        best_gain = 0  # Best information gain found\n",
    "        best_split = None  # Best split feature and threshold\n",
    "        best_left = None  # Best left split data\n",
    "        best_right = None  # Best right split data\n",
    "\n",
    "        n_samples, n_features = X.shape  # Number of samples and features\n",
    "        for feature in range(n_features):\n",
    "            thresholds = np.unique(X[:, feature])  # Unique values of the feature\n",
    "            for threshold in thresholds:\n",
    "                left_indices = X[:, feature] <= threshold  # Indices of samples in left split\n",
    "                right_indices = X[:, feature] > threshold  # Indices of samples in right split\n",
    "                y_left, y_right = y[left_indices], y[right_indices]  # Target values of left and right splits\n",
    "                gain = self._information_gain(y, y_left, y_right)  # Calculate information gain for this split\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain  # Update best gain\n",
    "                    best_split = (feature, threshold)  # Update best split\n",
    "                    best_left = (X[left_indices], y[left_indices])  # Update best left split data\n",
    "                    best_right = (X[right_indices], y[right_indices])  # Update best right split data\n",
    "\n",
    "        return best_gain, best_split, best_left, best_right\n",
    "\n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        # Recursively build the decision tree\n",
    "        n_samples, n_features = X.shape  # Number of samples and features\n",
    "\n",
    "        # Stop conditions for recursion\n",
    "        if n_samples == 0 or (self.max_depth is not None and depth >= self.max_depth):\n",
    "            # If no samples or max depth reached, create a leaf node\n",
    "            leaf_value = np.mean(y)  # Mean of the target values in the node\n",
    "            return {'leaf': True, 'value': leaf_value}\n",
    "\n",
    "        # Find the best split\n",
    "        gain, split, left, right = self._best_split(X, y)\n",
    "        if gain == 0:\n",
    "            # If no gain, create a leaf node with the mean of the target values\n",
    "            leaf_value = np.mean(y)\n",
    "            return {'leaf': True, 'value': leaf_value}\n",
    "\n",
    "        # Create the decision node\n",
    "        feature, threshold = split\n",
    "        left_branch = self._build_tree(*left, depth + 1)  # Recursively build the left branch\n",
    "        right_branch = self._build_tree(*right, depth + 1)  # Recursively build the right branch\n",
    "        return {'leaf': False, 'feature': feature, 'threshold': threshold, 'left': left_branch, 'right': right_branch}\n",
    "\n",
    "    def _predict_sample(self, sample, tree):\n",
    "        # Predict the target value of a single sample by traversing the tree\n",
    "        if tree['leaf']:\n",
    "            return tree['value']  # If leaf node, return the value\n",
    "        feature = tree['feature']\n",
    "        threshold = tree['threshold']\n",
    "        if sample[feature] <= threshold:\n",
    "            return self._predict_sample(sample, tree['left'])  # Traverse left if feature value <= threshold\n",
    "        else:\n",
    "            return self._predict_sample(sample, tree['right'])  # Traverse right if feature value > threshold\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Toy dataset\n",
    "    X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "    y = np.array([1.1, 1.9, 3.0, 3.9])\n",
    "\n",
    "    # Create and train the decision tree regressor\n",
    "    reg = DecisionTreeRegressor(max_depth=3)\n",
    "    reg.fit(X, y)\n",
    "\n",
    "    # Predict the target values for the same dataset\n",
    "    predictions = reg.predict(X)\n",
    "    print(\"Predictions:\", predictions)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeRegressor():\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None # stores the tree structure\n",
    "\n",
    "    def fit(self, X, y): # to the training data\n",
    "        self.tree = self._build_tree(X, y) # private method\n",
    "\n",
    "    def _mse(self, y): # mse of a leaf with mean being the average of all y target values in that leaf\n",
    "        '''\n",
    "        y = np.array([1.1, 1.9, 3.0, 3.9]) # y target values\n",
    "        mean = np.mean(y)\n",
    "\n",
    "        squared_differences = (y - mean) ** 2\n",
    "        squared_differences = ([1.1, 1.9, 3.0, 3.9] - 2.475) ** 2\n",
    "        squared_differences = [1.890625, 0.330625, 0.275625, 2.030625]\n",
    "\n",
    "        mse = np.mean(squared_differences)\n",
    "        '''\n",
    "        leaf_prediction = np.mean(y)\n",
    "        squared_differences = (y - leaf_prediction) ** 2\n",
    "        mse_leaf = np.mean(squared_differences)\n",
    "\n",
    "        return mse_leaf\n",
    "    \n",
    "    def _information_gain(self, y_left, y_right): # reduction in MSE after a new split by checking if the weighted MSE of both new child nodes is smaller than the MSE of the parent node\n",
    "        n = len(y) # values in the parent node\n",
    "        n_left, n_right = len(y_left), len(y_right) # observations in the child nodes\n",
    "        if n_left == 0 or n_right == 0: # return 0 information gain if any child node is empty\n",
    "            return 0\n",
    "        \n",
    "        weighted_avg_mse = (n_left / n) * self._mse(y_left) + (n_right / n) * self._mse(y_right)\n",
    "        parent_mse = self._mse(y) # parent node, before the split\n",
    "        information_gain = parent_mse - weighted_avg_mse\n",
    "        return information_gain\n",
    "    \n",
    "    def _best_split(self, X, y):\n",
    "\n",
    "        n_samples, n_features = X.shape # rows, columns\n",
    "        for feature in range(n_features):\n",
    "            thresholds = X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-12-3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
